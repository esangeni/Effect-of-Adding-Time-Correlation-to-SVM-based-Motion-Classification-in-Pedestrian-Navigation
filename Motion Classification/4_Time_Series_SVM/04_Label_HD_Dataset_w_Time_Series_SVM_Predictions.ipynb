{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Test the High Dimensional SVM Classifier**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">Eudald Sangenis  \n",
    "Creation: 7/13/2022  \n",
    "Last Update: 7/13/2022  \n",
    "\n",
    "The objective of this file is to test the High Dimensional SVM classifier:  \n",
    "\n",
    "Parameters of the trained High Dimensional Dataset:  \n",
    "- 6 magnitude signals  \n",
    "- timpe/sample window \n",
    "\n",
    "Once this classifier is tested the next step is to verify the navigation solution.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **<font size=\"5\">1. Libraries</font>**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **<font size=\"5\">2. Parameters to modify</font>**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">Boolean variable:\n",
    "* True: Predict the test datasets\n",
    "* False: Import already a done prediction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">Path High Dimensional Datasets to test the classifier:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dataset = 'test'       # train, test\n",
    "data_dataset = '2023_08_30' # 2022_03_17, 2022_04_25, 2022_07_27, 2022_08_01\n",
    "bias_dataset = True        # True (no Bias), False (Bias).\n",
    "num_df_used_to_train = 4    # 2 (2022_03_17 & 2022_04_25), 3 (2022_07_27 or 2022_08_01)\n",
    "num_window = 400             # 50, 100, 200, 400\n",
    "exp = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to read the labeled and HD datasets:\n",
    "dataset_path = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\HD_datasets\\\\'+data_dataset+'\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">Number components of PCA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">Path to the High Dimensional Classifier:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Loaded!\n"
     ]
    }
   ],
   "source": [
    "# Folder classifier:\n",
    "folder_clf = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'\n",
    "# Classifier Name:\n",
    "name_clf = str(num_window)+'HD_6sig_pca'+str(num_components)+'_no_bias_balanced_clf.sav'\n",
    "\n",
    "if prediction == True:\n",
    "    support = pickle.load(open(folder_clf + name_clf, 'rb'))    # read clf model\n",
    "    print('Classifier Loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">Path to the predicted labels dataset:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_label_predicted = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'\n",
    "l_predicted_name = data_dataset + '_HD'+str(num_window)+'_6sig_pca'+str(num_components)+'_exp'+str(exp)+'_Y_predicted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **<font size=\"5\">3. Load Trained Model Dataset:</font>**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_dataset_model = 'train'      # train, test\n",
    "# data_dataset_1 = '2022_03_17'\n",
    "# data_dataset_2 = '2022_04_25'\n",
    "# data_dataset_3 = '2022_07_27'\n",
    "# data_dataset_4 = '2022_08_01'\n",
    "\n",
    "# dataset_path_1 = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\HD_datasets\\\\'+data_dataset_1+'\\\\'\n",
    "# dataset_path_2 = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\HD_datasets\\\\'+data_dataset_2+'\\\\'\n",
    "# dataset_path_3 = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\HD_datasets\\\\'+data_dataset_3+'\\\\'\n",
    "# dataset_path_4 = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\HD_datasets\\\\'+data_dataset_4+'\\\\'\n",
    "# print('Reading datasets...')\n",
    "# # Load the HD dataset\n",
    "# if bias_dataset == False:\n",
    "#     if num_df_used_to_train == 2:\n",
    "#         df_1 = pd.read_csv(dataset_path_1 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "#         df_2 = pd.read_csv(dataset_path_2 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "\n",
    "#     if num_df_used_to_train == 3: \n",
    "#         df_1 = pd.read_csv(dataset_path_1 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "#         df_2 = pd.read_csv(dataset_path_2 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "#         df_3 = pd.read_csv(dataset_path_3 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "    \n",
    "#     if num_df_used_to_train == 4: \n",
    "#         df_1 = pd.read_csv(dataset_path_1 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "#         df_2 = pd.read_csv(dataset_path_2 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "#         df_3 = pd.read_csv(dataset_path_3 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "#         df_4 = pd.read_csv(dataset_path_4 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'.csv')\n",
    "\n",
    "# if bias_dataset == True:\n",
    "#     if num_df_used_to_train == 2:\n",
    "#         df_1 = pd.read_csv(dataset_path_1 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "#         df_2 = pd.read_csv(dataset_path_2 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "\n",
    "#     if num_df_used_to_train == 3: \n",
    "#         df_1 = pd.read_csv(dataset_path_1 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "#         df_2 = pd.read_csv(dataset_path_2 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "#         df_3 = pd.read_csv(dataset_path_3 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "    \n",
    "#     if num_df_used_to_train == 4: \n",
    "#         df_1 = pd.read_csv(dataset_path_1 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "#         df_2 = pd.read_csv(dataset_path_2 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "#         df_3 = pd.read_csv(dataset_path_3 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "#         df_4 = pd.read_csv(dataset_path_4 + 'HD_'+str(num_window)+'_6sig_'+type_dataset_model+'_no_Bias.csv')\n",
    "\n",
    "# print('Reading done!')\n",
    "\n",
    "# df_1 = df_1.drop(['Unnamed: 0'], axis=1)\n",
    "# df_2 = df_2.drop(['Unnamed: 0'], axis=1)\n",
    "# if num_df_used_to_train == 3: \n",
    "#     df_3 = df_3.drop(['Unnamed: 0'], axis=1)\n",
    "# if num_df_used_to_train == 4: \n",
    "#     df_3 = df_3.drop(['Unnamed: 0'], axis=1)\n",
    "#     df_4 = df_4.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "# if num_df_used_to_train == 2: df = pd.concat([df_1, df_2], axis=0)\n",
    "# if num_df_used_to_train == 3: df = pd.concat([df_1, df_2, df_3], axis=0)\n",
    "# if num_df_used_to_train == 4: df = pd.concat([df_1, df_2, df_3, df_4], axis=0)\n",
    "\n",
    "# del df_1, df_2\n",
    "# if num_df_used_to_train == 3: del df_3\n",
    "# if num_df_used_to_train == 4: del df_3, df_4\n",
    "\n",
    "# df = df.reset_index().drop('index', axis=1)\n",
    "\n",
    "# print('Shape concat dfs: ')\n",
    "# print(df.shape)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_model = df.iloc[:,:-1]\n",
    "# del df                      # delete variable to reduce memory\n",
    "# X_model.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARIZE DATA\n",
    "# scaler_model = StandardScaler()\n",
    "# scaler_model.fit(X_model)                       # fit with dataset that was used to train the model\n",
    "# X_norm_model = scaler_model.transform(X_model)  # transform the new datset\n",
    "# X_norm_model = pd.DataFrame(X_norm_model, columns=X_model.columns)\n",
    "# del X_model                         # delete variable to reduce memory\n",
    "# X_norm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **<font size=\"5\">3. Load Test Dataset:</font>**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset 2023_08_30 ...\n",
      "Reading done!\n",
      "Shapes 2023_08_30: \n",
      "(61309, 2406)\n"
     ]
    }
   ],
   "source": [
    "print('Reading dataset ' + data_dataset + ' ...')\n",
    "# Load the HD dataset\n",
    "    # if bias_dataset == False: df = pd.read_csv(dataset_path + 'HD_'+str(num_window)+'_6sig_'+type_dataset+'.csv')\n",
    "    # if bias_dataset == True: df = pd.read_csv(dataset_path + 'HD_'+str(num_window)+'_6sig_'+type_dataset+'_no_Bias.csv')\n",
    "\n",
    "# Only for unlabeled datasets for navigation solution (GOOD CODE above):\n",
    "dataset_path = 'G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\HD_datasets\\\\'+data_dataset+'\\\\'\n",
    "df = pd.read_csv(dataset_path + 'HD_'+str(num_window)+'_6sig_exp'+str(exp)+'_no_Bias.csv')\n",
    "\n",
    "print('Reading done!')\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "print('Shapes '+data_dataset+': ')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1_t400</th>\n",
       "      <th>acc2_t400</th>\n",
       "      <th>acc3_t400</th>\n",
       "      <th>gyro1_t400</th>\n",
       "      <th>gyro2_t400</th>\n",
       "      <th>gyro3_t400</th>\n",
       "      <th>acc1_t399</th>\n",
       "      <th>acc2_t399</th>\n",
       "      <th>acc3_t399</th>\n",
       "      <th>gyro1_t399</th>\n",
       "      <th>...</th>\n",
       "      <th>acc3_t1</th>\n",
       "      <th>gyro1_t1</th>\n",
       "      <th>gyro2_t1</th>\n",
       "      <th>gyro3_t1</th>\n",
       "      <th>acc1_t0</th>\n",
       "      <th>acc2_t0</th>\n",
       "      <th>acc3_t0</th>\n",
       "      <th>gyro1_t0</th>\n",
       "      <th>gyro2_t0</th>\n",
       "      <th>gyro3_t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>-0.004955</td>\n",
       "      <td>-0.004336</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.005277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003661</td>\n",
       "      <td>-0.008725</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.008894</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.005277</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.003813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.008894</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>-0.00353</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>-0.008207</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2406 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc1_t400  acc2_t400  acc3_t400  gyro1_t400  gyro2_t400  gyro3_t400  \\\n",
       "0   0.006228   0.008727  -0.004955   -0.004336    0.000138    0.000926   \n",
       "1   0.006411   0.009501   0.000046   -0.005277    0.000188    0.000555   \n",
       "\n",
       "   acc1_t399  acc2_t399  acc3_t399  gyro1_t399  ...   acc3_t1  gyro1_t1  \\\n",
       "0   0.006411   0.009501   0.000046   -0.005277  ... -0.003661 -0.008725   \n",
       "1   0.000045   0.004815   0.000036   -0.003813  ... -0.002704 -0.008894   \n",
       "\n",
       "   gyro2_t1  gyro3_t1  acc1_t0   acc2_t0   acc3_t0  gyro1_t0  gyro2_t0  \\\n",
       "0  0.005248 -0.000339 -0.00024 -0.002519 -0.002704 -0.008894  0.005561   \n",
       "1  0.005561  0.001362 -0.00353  0.002462  0.000393 -0.008207  0.004986   \n",
       "\n",
       "   gyro3_t0  \n",
       "0  0.001362  \n",
       "1  0.000880  \n",
       "\n",
       "[2 rows x 2406 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test dataset:')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **<font size=\"5\">4. Normalize data:</font>**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1_t400</th>\n",
       "      <th>acc2_t400</th>\n",
       "      <th>acc3_t400</th>\n",
       "      <th>gyro1_t400</th>\n",
       "      <th>gyro2_t400</th>\n",
       "      <th>gyro3_t400</th>\n",
       "      <th>acc1_t399</th>\n",
       "      <th>acc2_t399</th>\n",
       "      <th>acc3_t399</th>\n",
       "      <th>gyro1_t399</th>\n",
       "      <th>...</th>\n",
       "      <th>acc3_t1</th>\n",
       "      <th>gyro1_t1</th>\n",
       "      <th>gyro2_t1</th>\n",
       "      <th>gyro3_t1</th>\n",
       "      <th>acc1_t0</th>\n",
       "      <th>acc2_t0</th>\n",
       "      <th>acc3_t0</th>\n",
       "      <th>gyro1_t0</th>\n",
       "      <th>gyro2_t0</th>\n",
       "      <th>gyro3_t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174429</td>\n",
       "      <td>0.052085</td>\n",
       "      <td>0.127753</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.043845</td>\n",
       "      <td>0.174565</td>\n",
       "      <td>0.052819</td>\n",
       "      <td>0.131950</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128840</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.01226</td>\n",
       "      <td>0.042890</td>\n",
       "      <td>0.169616</td>\n",
       "      <td>0.041374</td>\n",
       "      <td>0.129643</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.044176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174565</td>\n",
       "      <td>0.052819</td>\n",
       "      <td>0.131950</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.010652</td>\n",
       "      <td>0.043565</td>\n",
       "      <td>0.169826</td>\n",
       "      <td>0.048373</td>\n",
       "      <td>0.131942</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129643</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.01236</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.132242</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.043811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2406 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc1_t400  acc2_t400  acc3_t400  gyro1_t400  gyro2_t400  gyro3_t400  \\\n",
       "0   0.174429   0.052085   0.127753    0.004046    0.010636    0.043845   \n",
       "1   0.174565   0.052819   0.131950    0.003484    0.010652    0.043565   \n",
       "\n",
       "   acc1_t399  acc2_t399  acc3_t399  gyro1_t399  ...   acc3_t1  gyro1_t1  \\\n",
       "0   0.174565   0.052819   0.131950    0.003484  ...  0.128840  0.001428   \n",
       "1   0.169826   0.048373   0.131942    0.004358  ...  0.129643  0.001327   \n",
       "\n",
       "   gyro2_t1  gyro3_t1   acc1_t0   acc2_t0   acc3_t0  gyro1_t0  gyro2_t0  \\\n",
       "0   0.01226  0.042890  0.169616  0.041374  0.129643  0.001327  0.012360   \n",
       "1   0.01236  0.044176  0.167167  0.046100  0.132242  0.001737  0.012177   \n",
       "\n",
       "   gyro3_t0  \n",
       "0  0.044176  \n",
       "1  0.043811  \n",
       "\n",
       "[2 rows x 2406 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STANDARIZE DATA\n",
    "# scaler_train = StandardScaler()\n",
    "# scaler_train.fit(X_model)           # fit with dataset that was used to train the model\n",
    "# del X_model                         # delete variable to reduce memory\n",
    "\n",
    "scaler_model = pickle.load(open('G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'+str(num_window)+'HD_6sig_pca'+str(num_components)+'_scaler.pkl','rb'))\n",
    "\n",
    "X_norm = scaler_model.transform(X)  # transform the new datset\n",
    "X_norm = pd.DataFrame(X_norm, columns = df.columns)\n",
    "X_norm.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **<font size=\"5\">5. PCA:</font>**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_acc_x = decomposition.PCA(n_components = num_components).fit(X_norm_model.iloc[:,0::6])   # fit with the normalization of the model trained dataset\n",
    "# pca_acc_y = decomposition.PCA(n_components = num_components).fit(X_norm_model.iloc[:,1::6])\n",
    "# pca_acc_z = decomposition.PCA(n_components = num_components).fit(X_norm_model.iloc[:,2::6])\n",
    "# pca_gyr_x = decomposition.PCA(n_components = num_components).fit(X_norm_model.iloc[:,3::6])\n",
    "# pca_gyr_y = decomposition.PCA(n_components = num_components).fit(X_norm_model.iloc[:,4::6])\n",
    "# pca_gyr_z = decomposition.PCA(n_components = num_components).fit(X_norm_model.iloc[:,5::6])\n",
    "# del X_norm_model # delete variable to reduce memory\n",
    "\n",
    "pca_acc_x = pickle.load(open('G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'+str(num_window)+'HD_6sig_pca'+str(num_components)+'_PCA_acc_x.pkl','rb'))\n",
    "pca_acc_y = pickle.load(open('G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'+str(num_window)+'HD_6sig_pca'+str(num_components)+'_PCA_acc_y.pkl','rb'))\n",
    "pca_acc_z = pickle.load(open('G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'+str(num_window)+'HD_6sig_pca'+str(num_components)+'_PCA_acc_z.pkl','rb'))\n",
    "pca_gyr_x = pickle.load(open('G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'+str(num_window)+'HD_6sig_pca'+str(num_components)+'_PCA_gyr_x.pkl','rb'))\n",
    "pca_gyr_y = pickle.load(open('G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'+str(num_window)+'HD_6sig_pca'+str(num_components)+'_PCA_gyr_y.pkl','rb'))\n",
    "pca_gyr_z = pickle.load(open('G:\\\\Shared drives\\\\NIST-Pedestrian Activity Classification\\\\motion classification\\\\6_HD_6sig_SVM_Paper_Results\\\\'+str(num_window)+'HD_6sig_pca'+str(num_components)+'_PCA_gyr_z.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Linear Acceleration X projected training data is:(61309, 6)\n",
      "The shape of the Linear Acceleration Y projected training data is:(61309, 6)\n",
      "The shape of the Linear Acceleration Z projected training data is:(61309, 6)\n",
      "The shape of the Angular Velocity X projected training data is:(61309, 6)\n",
      "The shape of the Angular Velocity Y projected training data is:(61309, 6)\n",
      "The shape of the Angular Velocity Z projected training data is:(61309, 6)\n"
     ]
    }
   ],
   "source": [
    "# Project data to its dimensional reduction space\n",
    "X_projected_acc_x = pca_acc_x.transform(X_norm.iloc[:,0::6])\n",
    "print('The shape of the Linear Acceleration X projected training data is:' + str(X_projected_acc_x.shape))\n",
    "X_projected_acc_y = pca_acc_y.transform(X_norm.iloc[:,1::6])\n",
    "print('The shape of the Linear Acceleration Y projected training data is:' + str(X_projected_acc_y.shape))\n",
    "X_projected_acc_z = pca_acc_z.transform(X_norm.iloc[:,2::6])\n",
    "print('The shape of the Linear Acceleration Z projected training data is:' + str(X_projected_acc_z.shape))\n",
    "\n",
    "X_projected_gyr_x = pca_gyr_x.transform(X_norm.iloc[:,3::6])\n",
    "print('The shape of the Angular Velocity X projected training data is:' + str(X_projected_gyr_x.shape))\n",
    "X_projected_gyr_y = pca_gyr_y.transform(X_norm.iloc[:,4::6])\n",
    "print('The shape of the Angular Velocity Y projected training data is:' + str(X_projected_gyr_y.shape))\n",
    "X_projected_gyr_z = pca_gyr_z.transform(X_norm.iloc[:,5::6])\n",
    "print('The shape of the Angular Velocity Z projected training data is:' + str(X_projected_gyr_z.shape))\n",
    "\n",
    "# Name of the columns of the pca dataset\n",
    "colnames = []\n",
    "for i in range(1,6*num_components+1):\n",
    "    colnames = np.concatenate((colnames, [f'comp_{i}']))\n",
    "colnames\n",
    "\n",
    "X_projected = pd.concat([pd.DataFrame(X_projected_acc_x),pd.DataFrame(X_projected_acc_y),pd.DataFrame(X_projected_acc_z), pd.DataFrame(X_projected_gyr_x), pd.DataFrame(X_projected_gyr_y), pd.DataFrame(X_projected_gyr_z)], axis = 1)\n",
    "X_projected.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The projected test data in the number of components is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_1</th>\n",
       "      <th>comp_2</th>\n",
       "      <th>comp_3</th>\n",
       "      <th>comp_4</th>\n",
       "      <th>comp_5</th>\n",
       "      <th>comp_6</th>\n",
       "      <th>comp_7</th>\n",
       "      <th>comp_8</th>\n",
       "      <th>comp_9</th>\n",
       "      <th>comp_10</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_27</th>\n",
       "      <th>comp_28</th>\n",
       "      <th>comp_29</th>\n",
       "      <th>comp_30</th>\n",
       "      <th>comp_31</th>\n",
       "      <th>comp_32</th>\n",
       "      <th>comp_33</th>\n",
       "      <th>comp_34</th>\n",
       "      <th>comp_35</th>\n",
       "      <th>comp_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.041144</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>-1.429861</td>\n",
       "      <td>-0.006469</td>\n",
       "      <td>-0.431791</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>0.215301</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>-0.257503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161913</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>-0.087532</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>0.077658</td>\n",
       "      <td>-0.017486</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.320713</td>\n",
       "      <td>-0.706081</td>\n",
       "      <td>-0.006590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.041044</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>-1.429521</td>\n",
       "      <td>-0.006521</td>\n",
       "      <td>-0.431562</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.022487</td>\n",
       "      <td>0.215336</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>-0.257789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161777</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>-0.087814</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>0.077292</td>\n",
       "      <td>-0.017487</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.320536</td>\n",
       "      <td>-0.706264</td>\n",
       "      <td>-0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.040952</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>-1.429302</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>-0.431458</td>\n",
       "      <td>-0.004987</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>0.215438</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>-0.258099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161634</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>-0.088057</td>\n",
       "      <td>-0.003479</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>-0.017517</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.320402</td>\n",
       "      <td>-0.706442</td>\n",
       "      <td>-0.006763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.040881</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>-1.429433</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>-0.431690</td>\n",
       "      <td>-0.005005</td>\n",
       "      <td>0.021943</td>\n",
       "      <td>0.215483</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>-0.258324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161498</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>-0.088326</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>0.076562</td>\n",
       "      <td>-0.017554</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>-0.706640</td>\n",
       "      <td>-0.006757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.040810</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>-1.429556</td>\n",
       "      <td>-0.006840</td>\n",
       "      <td>-0.431919</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.215224</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>-0.258245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161360</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>-0.088578</td>\n",
       "      <td>-0.003910</td>\n",
       "      <td>0.076214</td>\n",
       "      <td>-0.017599</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.319843</td>\n",
       "      <td>-0.706848</td>\n",
       "      <td>-0.006706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61304</th>\n",
       "      <td>-2.940278</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>-1.372793</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>-0.416206</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>-0.002781</td>\n",
       "      <td>0.249860</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>-0.272266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162524</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.082509</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.077325</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.324660</td>\n",
       "      <td>-0.710441</td>\n",
       "      <td>-0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61305</th>\n",
       "      <td>-2.940262</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>-1.372653</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>-0.415931</td>\n",
       "      <td>-0.006426</td>\n",
       "      <td>-0.002956</td>\n",
       "      <td>0.249730</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.272079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162351</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>-0.082447</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.077375</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.324564</td>\n",
       "      <td>-0.710473</td>\n",
       "      <td>-0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61306</th>\n",
       "      <td>-2.940245</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>-1.372506</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>-0.415648</td>\n",
       "      <td>-0.006668</td>\n",
       "      <td>-0.003158</td>\n",
       "      <td>0.249855</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>-0.272110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162186</td>\n",
       "      <td>0.008715</td>\n",
       "      <td>-0.082430</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.077439</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.324361</td>\n",
       "      <td>-0.710524</td>\n",
       "      <td>-0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61307</th>\n",
       "      <td>-2.940235</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>-1.372517</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>-0.415508</td>\n",
       "      <td>-0.006867</td>\n",
       "      <td>-0.003094</td>\n",
       "      <td>0.250175</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>-0.272310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162015</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>-0.082394</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.077510</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.324109</td>\n",
       "      <td>-0.710585</td>\n",
       "      <td>-0.000746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61308</th>\n",
       "      <td>-2.940212</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>-1.372356</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>-0.415205</td>\n",
       "      <td>-0.007119</td>\n",
       "      <td>-0.002824</td>\n",
       "      <td>0.250611</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>-0.272613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161835</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>-0.082308</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.077587</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.323820</td>\n",
       "      <td>-0.710658</td>\n",
       "      <td>-0.000998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61309 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         comp_1    comp_2    comp_3    comp_4    comp_5    comp_6    comp_7  \\\n",
       "0     -3.041144  0.010439 -1.429861 -0.006469 -0.431791 -0.005011  0.022890   \n",
       "1     -3.041044  0.010327 -1.429521 -0.006521 -0.431562 -0.005039  0.022487   \n",
       "2     -3.040952  0.010106 -1.429302 -0.006451 -0.431458 -0.004987  0.022092   \n",
       "3     -3.040881  0.009985 -1.429433 -0.006497 -0.431690 -0.005005  0.021943   \n",
       "4     -3.040810  0.010124 -1.429556 -0.006840 -0.431919 -0.005208  0.021906   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61304 -2.940278  0.000547 -1.372793  0.002635 -0.416206 -0.006250 -0.002781   \n",
       "61305 -2.940262  0.000763 -1.372653  0.002402 -0.415931 -0.006426 -0.002956   \n",
       "61306 -2.940245  0.001063 -1.372506  0.002061 -0.415648 -0.006668 -0.003158   \n",
       "61307 -2.940235  0.001317 -1.372517  0.001771 -0.415508 -0.006867 -0.003094   \n",
       "61308 -2.940212  0.001649 -1.372356  0.001387 -0.415205 -0.007119 -0.002824   \n",
       "\n",
       "         comp_8    comp_9   comp_10  ...   comp_27   comp_28   comp_29  \\\n",
       "0      0.215301  0.001803 -0.257503  ... -0.161913  0.008275 -0.087532   \n",
       "1      0.215336  0.001956 -0.257789  ... -0.161777  0.008196 -0.087814   \n",
       "2      0.215438  0.002124 -0.258099  ... -0.161634  0.008148 -0.088057   \n",
       "3      0.215483  0.002607 -0.258324  ... -0.161498  0.008050 -0.088326   \n",
       "4      0.215224  0.003236 -0.258245  ... -0.161360  0.007901 -0.088578   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "61304  0.249860  0.003420 -0.272266  ... -0.162524  0.008671 -0.082509   \n",
       "61305  0.249730  0.003367 -0.272079  ... -0.162351  0.008700 -0.082447   \n",
       "61306  0.249855  0.003277 -0.272110  ... -0.162186  0.008715 -0.082430   \n",
       "61307  0.250175  0.003517 -0.272310  ... -0.162015  0.008732 -0.082394   \n",
       "61308  0.250611  0.004020 -0.272613  ... -0.161835  0.008779 -0.082308   \n",
       "\n",
       "        comp_30   comp_31   comp_32   comp_33   comp_34   comp_35   comp_36  \n",
       "0     -0.003130  0.077658 -0.017486  0.002601  0.320713 -0.706081 -0.006590  \n",
       "1     -0.003327  0.077292 -0.017487  0.002681  0.320536 -0.706264 -0.006723  \n",
       "2     -0.003479  0.076919 -0.017517  0.002711  0.320402 -0.706442 -0.006763  \n",
       "3     -0.003673  0.076562 -0.017554  0.002722  0.320158 -0.706640 -0.006757  \n",
       "4     -0.003910  0.076214 -0.017599  0.002716  0.319843 -0.706848 -0.006706  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "61304  0.006055  0.077325  0.001462  0.000461  0.324660 -0.710441 -0.000484  \n",
       "61305  0.005847  0.077375  0.001447  0.000491  0.324564 -0.710473 -0.000592  \n",
       "61306  0.005621  0.077439  0.001385  0.000458  0.324361 -0.710524 -0.000598  \n",
       "61307  0.005396  0.077510  0.001388  0.000519  0.324109 -0.710585 -0.000746  \n",
       "61308  0.005200  0.077587  0.001440  0.000650  0.323820 -0.710658 -0.000998  \n",
       "\n",
       "[61309 rows x 36 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_projected['label'] = Y\n",
    "print('The projected test data in the number of components is:')\n",
    "X_projected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **<font size=\"5\">6. Prediction Model</font>**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Prediction done!\n"
     ]
    }
   ],
   "source": [
    "if prediction == True:\n",
    "    print('Predicting...')\n",
    "    Y_predicted = support.predict(X)\n",
    "    print('Prediction done!')\n",
    "    Y_predicted_df = pd.DataFrame(Y_predicted, columns = ['predicted_l'])\n",
    "    Y_predicted_df.to_csv(folder_label_predicted + l_predicted_name)\n",
    "    Y_predicted = pd.read_csv(folder_label_predicted + l_predicted_name)\n",
    "else:\n",
    "    Y_predicted = pd.read_csv(folder_label_predicted + l_predicted_name)\n",
    "    print('L Predicted Loaded!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9103196f9419d8fa895c36bf5b3852f32d27a01beb0b11d5bcec3c7795f6c22a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
